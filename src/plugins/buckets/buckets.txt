The buckets plugin
==================

The idea behind this plugin is statistical detection of anomalies.
It's loosely based on the method from Guillaume Dewaele, Kensuke
Fukuda, Pierre Borgnat, Patrice Abry and Kenjiro Cho.

We have several independent hash functions and a set of buckets for
each of the functions. The buckets keep counts of packets that belong
into the bucket according to the hash function (just like a hash
table, but not holding the actual packets, only their counts).

Each time a packet comes, we extract some interesting part (let's say
an IP address) and hash it by each hash function. Then we increment
the number in each of the buckets.

After a short time, we start with new set of empty buckets (and keep
the old ones for now).

Once in a while, the server asks for the counts. We send the counts
for the server to analyze them. The server aggregates the counts from
several clients and keeps history of them. When it sees the counts
don't look statistically right, it identifies the outstanding bucket
indices (one or more index in each of the hash functions). It then
asks the client for keys for the keys.

The client drops the buckets on each send of the counts, but it
keeps few snapshots of the keys, so it can answer the query for keys from
server. When the query comes, it unifies keys for indices in the same
hash functions and intersects the hash functions. What is outstanding
in each hash function is probably an anomaly. The set of keys is sent
to the server.

Communication protocol
----------------------

The messages sent between the server plugin and client plugin all
begin with an opcode byte, similarly to the main protocol.

The configuration message
~~~~~~~~~~~~~~~~~~~~~~~~~

When the client connects, it asks for configuration. It sends a
message with the `C` opcode, without any parameters. The server
answers with current configuration.

Also, the server can send a configuration update without being asked.
Currently, the plugin doesn't handle that gracefully, and restarts
itself (asking for the configuration again), but it is considered only
small annoyance to fix.

The configuration looks like this (all encoded in network byte order,
without any paddings):

`C`::
  single byte opcode.
seed::
  `uint64_t`. Seed used to initialize the random hash
  functions.
timestamp::
  `uint64_t`. Current server time. Will be used as a
  start mark of the current snapshot of data.
bucket count::
  `uint32_t`. Number of buckets per hash function.
hash count::
  `uint32_t`. Number of hash functions to use.
criteria count::
  `uint32_t`. Number of different ``pieces'' of the
  packet to hash by. The client supports analysing different aspects
  of the packets at once, this is the number of aspects that should be
  analysed.
history size::
  `uint32_t`. How much older versions to keep for
  requests from server. If this is set to 2, for example, then
  there'll be three copies of the data. One is the current one that is
  being incremented by each packet that comes, and two last snapshots
  which we already sent to the server.
config version::
  `uint32_t`. Version of the config, can be used by
  the server to recognize the counts sent are for different version of
  configuration that the server is using, detecting inconsistencies.
max_key_count::
  `uint32_t`. The maximum number of keys stored per one criterion and
  generation. This is to limit memory consumption.
max_timeslots::
  `uint32_t`. The maximum number of buckets for each index between two
  server requests for counts. This is to cap the limit of memory used
  by the collector. If more are needed, it stops collecting.
time_granularity::
  `uint32_t`. How often to switch to empty buckets. After collecting
  for so many milliseconds, new buckets are started.
List of criteria to use::
  Each one is single character, from the list below, specifying one
  criterion.

Sending the counts
~~~~~~~~~~~~~~~~~~

When the server wants to get the new counts, it sends the `G` opcode
(stands for next Generation), followed by `uint64_t` timestamp. The
timestamp is server time and it identifies the start of next
generation.

The client answers with the message looking like this:

`G`::
  single byte opcode
timestamp::
  `uint64_t`. Starting time of the generation being sent,
  as specified in previous request or configuration. The server can
  check that the data is really from the desired time period.
config version::
  `uint32_t`. The version used by the client, for
  detecting inconsistencies on server.
timeslots::
  `uint32_t`. Number of time slots actually used. This is how many
  counts will be transmitted for each index & hash. In case the client
  stopped gathering because it run out of empty buckets (eg.
  `max_timeslots` has been reached), this is 0 and no data is sent.
The data of criteria::
  The criteria are listed in the same order as they were in the
  config, one by one.

One criterion is:

overflow flag::
  `uint32_t`. When there's an overflow on that
  criterion, this is set to non-zero. See below for details about the
  overflow.
counts::
  Bucket timeslots * count * hash count `uint32_t`. Each hash is
  together.  If we had 4 buckets and 2 hashes, it would look like (the
  parentheses are just for orientation):
+
  (h1-b1, h1-b2, h1-b3, h1-b4), (h2-b1, h2-b2, h2-b3, h2-b4)
+
Each of the items there is an array of `timeslots` uint32_t
integers, representing the number of gathered in that bucket in each
of the times.

Sending the keys
~~~~~~~~~~~~~~~~

When the server wants to know a set of keys for some identified
indices, it sends following message. All indices are 0-based:

`K`::
  Single byte opcode.
timestamp::
  `uint64_t`. The timestamp at which the generation the server is
  interested in started. The client searches the available generations
  and identifies the one that matches.
req_id::
  `uint_32_t`. This is opaque data which will be included with the
  answer, so the server can match the answer with the query.
criterion::
  `uint32_t`. The index of criterion to consider.
indices of the buckets::
  Bunch of `uint32_t`s. There's one number saying how many buckets are
  interesting in the given hash, then so many indices are present.
  Then, the same repeats for the next hash. Therefore, if we had 2
  hashes and 4 buckets and were interested in 1, 3, 4 in the first
  hash and 2 in the second, it would look like this (parentheses again
  just for readability):
+
  (3, 1, 3, 4), (1, 2)

If the generation with requested timestamp isn't found, the client
sends a message containing only `M` and the `req_id`.

If it is found, a message with this format is sent:

`K`::
  Single byte opcode.
req_id::
  `uint32_t`. The request id, copied from the request message.
key set::
  One key after another. Type (and length) of each key depends on the
  criterion used.

Available criteria
------------------

The plugin supports several criteria to hash by. They are identified
by single character each:

`P`::
  The port (UDP or TCP) of the remote side. Encoded as 2-byte unsigned
  integer in network byte order.
`I`::
  The IP address of the remote side. Encoded as 17 bytes. The first
  byte is version used (`0x04` or `0x06` for IPv4 or IPv6). Then in
  case of IPv6 address, there are 16 bytes of the address, as
  transmitted on the network. In case of IPv4, it is only 4 bytes of
  the address and the rest is padded with zeroes.
`B`::
  Both the remote port and IP address. It is encoded as 19 bytes,
  first 2 bytes for the port, than 17 bytes for the address.
`L`::
  Similar to `B`, but the port carried is the local one.

Also, there are lower-case variants of those. These consider only
outbound non-ICMP packets. This has the advantage of not getting
cluttered by inbound packets dropped by firewall (nor by ICMP packets
refusing them), while still preserving all the bidirectional
connections.

The hashes used
---------------

For each hash, we generate bunch of random data. We then index the
data by the bytes in the key and xor them together.

With independent random data, they should be independent hash
functions. The only problem is, we need the same random data on all
the clients.

We have our own random number generator implementation, so we can be
sure it computes the same random data. We also provide the same seed
from the server.

The overflow handling
---------------------

Each unique key seen is stored in the current generation. But, if the
maximum number of keys in that criterion is reached, the criterion
does not store any more keys (until new generation is started) and the
overflow flag is set to 1.

This way, the server can know the set would be incomplete. The counts
are still complete, though.

This is needed to prevent the analyzer to eat all available memory,
while it should happen only rarely with usual use, since the limit
would be large enough and users usually communicate with only few end
points.

The analysis
------------

This is a simplified version of the server does to find anomalies. See
the code for exact implementation.

We consider data of each hash function independently.

First, it aggregates data from all the client answers in the
generation, by summing the clients together. This simulates the
situation if we gathered all the data at one point, not at many
clients.

We then concatenate the buckets with few older generations stored in
the server, to produce longer interval.

Then we form aggregation levels of the data. We group (sum) data in
pairs of adjoining time slots, then quadruples, groups of 8, etc.

In each aggregation level, we claim each bucket is a separate random
variable with several samples and compute the parameters of gamma
distribution on it. Then we compute ``average'' gamma parameters of
all the buckets. Here, average means mean and variance.

Then, we take all the aggregation levels together. We compute a
distance of the list of parameters of each bucket from the list of
average parameters. If that distance is too large, we say the bucket
is anomalous.
